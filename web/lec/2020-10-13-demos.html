---
title:      OpenMP demos
layout:     main
---

<p>This file has a number of small demos of OpenMP constructs. It must be compiled with the OpenMP flags turned on (see the various <code>Makefile.in</code> files to see how to do this with different compilers).</p>
<p>Any code that uses OpenMP is going to include the <code>omp.h</code> header, where the various OpenMP library routines are declared.</p>
<pre><code>#include &lt;omp.h&gt;</code></pre>
<h2 id="hello-world">Hello, world</h2>
<p>This routine uses <code>omp_get_thread_num</code> and <code>omp_get_num_threads</code> to tell us the index of the current thread and the total number of threads in the region</p>
<pre><code>void hello()
{
    #pragma omp parallel
    printf(&quot;Hello world from %d / %d\n&quot;, 
           omp_get_thread_num(), omp_get_num_threads());
}</code></pre>
<h2 id="shared-and-private">Shared and private</h2>
<p>The <code>hello</code> routine doesn’t do anything interesting with memory. Here are two of the simplest possible examples that actually do something, even if it is just filling an array. We’ve included a couple of additional tweaks here that aren’t in the slides:</p>
<ul>
<li>We use <code>omp_get_max_threads()</code> to determine the size of the array that the threads write to. This tells us the maximum number of threads allowed.</li>
<li>We use <code>omp_get_num_threads()</code> to tell how many threads we actually got. Note that <code>omp_get_num_threads()</code> tells the number of threads <em>in the current parallel section</em>. So it has to be called from within the parallel section, not outside. We use the <code>lastprivate</code> variable declaration to make sure that the <code>nthreads</code> variable gets copied out to the outside world when the parallel region ends.</li>
<li><p>We use a variable-length array for the output. This is technically optional in C11 (it was required in C99), but all the common compilers support it, including CLang, Intel, and GCC.</p>
<p>void fill_array1() { int max_threads = omp_get_max_threads(); int i; int s[max_threads]; memset(s, 0, max_threads * sizeof(int)); #pragma omp parallel shared(s) private(i) { i = omp_get_thread_num(); s[i] = i; } print_array(“fill_array1:”, s, max_threads); }</p>
<p>void fill_array2() { int max_threads = omp_get_max_threads(); int s[max_threads]; memset(s, 0, max_threads * sizeof(int)); #pragma omp parallel { int i = omp_get_thread_num(); s[i] = i; } print_array(“fill_array1:”, s, max_threads); }</p></li>
</ul>
<h2 id="monte-carlo-and-reductions">Monte Carlo and reductions</h2>
<p>This is a Monte Carlo experiment to compute <span class="math inline"><em>π</em>/4</span>. We are going to run this on several different threads, so we need to use different pseudo-random number streams for each thread. The <code>rand48</code> family of random number generators is not great, but the better alternatives mostly involve bringing in external libraries, so we’ll leave be.</p>
<pre><code>double mc_pi(int ntrials, uint64_t seed)
{
    double sumX = 0.0;
    for (int i = 0; i &lt; ntrials; ++i) {
        double x = erand48((unsigned short*) &amp;seed);
        double y = erand48((unsigned short*) &amp;seed);
        if (x*x + y*y &lt; 1)
            sumX += 1.0;
    }
    return sumX;
}

void omp_mc_pi(int ntrials)
{
    int max_threads = omp_get_max_threads();
    uint64_t seeds[max_threads];
    for (int i = 0; i &lt; max_threads; ++i)
        seeds[i] = lrand48();

    double sum = 0.0;
    int all_trials = 0;
    #pragma omp parallel reduction(+:sum) reduction(+:all_trials)
    {
        sum = mc_pi(ntrials, seeds[omp_get_thread_num()]);
        all_trials = ntrials;
    }

    printf(&quot;Estimate %g (vs %g) from %d trials\n&quot;,
           4*sum/all_trials, M_PI, all_trials);
}</code></pre>
<h2 id="linked-list-and-critical-sections">Linked list and critical sections</h2>
<p>Critical sections are good for protecting data structures from inconsistencies during updates. As an example, let’s consider a linked list data structure that is concurrently updated by several threads. Note that if we have several linked lists, we still end up with just one critical section! So finer-grain control might make sense in that case.</p>
<pre><code>typedef struct link_t {
    struct link_t* next;
    int data;
} link_t;

void list_push(link_t** l, int data)
{
    link_t* link = (link_t*) malloc(sizeof(link_t));
    link-&gt;data = data;
    #pragma omp critical(list_cs)
    {
        link-&gt;next = *l;
        *l = link;
    }
}

void print_list(const char* s, link_t* l)
{
    printf(&quot;%s:&quot;, s);
    while (l != NULL) {
        printf(&quot; %d&quot;, l-&gt;data);
        l = l-&gt;next;
    }
    printf(&quot;\n&quot;);
}

void free_list(link_t* l)
{
    while (l != NULL) {
        link_t* lnext = l-&gt;next;
        free(l);
        l = l-&gt;next;
    }
}

void list_test()
{
    link_t* l = NULL;
    #pragma omp parallel for
    for (int i = 0; i &lt; 10; ++i)
        list_push(&amp;l, i);
    print_list(&quot;list_test&quot;, l);
    free_list(l);
}

void list_push2(link_t** l, int data)
{
    link_t* link = (link_t*) malloc(sizeof(link_t));
    link-&gt;data = data;
    #pragma omp atomic capture
    {
        link-&gt;next = *l;
        *l = link;
    }
}</code></pre>
<h2 id="linked-list-and-atomic-capture">Linked list and atomic capture</h2>
<p>The linked list example above uses a critical section to protect the list push operation. The version below uses an atomic capture operation (i.e. an atomic operation that reads out the old value from some memory and replaces it with a new value). This atomic capture approach is finer-grained than the critical section; for example, we would not have any contention when using this approach to update two distinct lists concurrently.</p>
<pre><code>void list_test2()
{
    link_t* l = NULL;
    #pragma omp parallel for
    for (int i = 0; i &lt; 10; ++i)
        list_push(&amp;l, i);
    print_list(&quot;list_test&quot;, l);
    free_list(l);
}</code></pre>
<h2 id="atomic-updates">Atomic updates</h2>
<p>The mo common use of atomic operations is to update small shared data items - counters, most often.</p>
<pre><code>void count_evens()
{
    int counts[2] = {0, 0};
    #pragma omp parallel for
    for (int i = 0; i &lt; 100; ++i) {
        int which_counter = (i % 2);
        #pragma omp atomic
        counts[which_counter]++;
    }
    printf(&quot;For 0 to 99: %d evens, %d odds\n&quot;, counts[0], counts[1]);
}</code></pre>
<h2 id="barrier-based-synchronization">Barrier-based synchronization</h2>
<p>Barrier-based synchronization is particularly useful when we have computations organized into distinct time steps or phases, with each step depending on data written in the previous step. We’ve seen a few such computations, including the 1D wave equation. For this example, without attempting to make anything go fast, let’s try the Game of Life.</p>
<p>We start with some (non-parallel) setup. We’ll use a simple glider pattern to test things out - this pattern translates by one cell horizontally and vertically once every four generations.</p>
<pre><code>#define NLIFE 100

typedef struct life_board_t {
    uint8_t cells[2][NLIFE][NLIFE];
} life_board_t;

const char* glider =
    &quot; *\n&quot;
    &quot;  *\n&quot;
    &quot;***\n&quot;;

void init_life(life_board_t* board, const char* s)
{
    memset(board-&gt;cells, 0, 2 * NLIFE * NLIFE);
    for (int i = 1; i &lt; NLIFE-1 &amp;&amp; *s != &#39;\0&#39;; ++i) {
        int live = 0;
        for (int j = 1; *s &amp;&amp; *s != &#39;\n&#39;; ++j, ++s) {
            if (i &lt; NLIFE-1) {
                if (*s == &#39; &#39;)
                    board-&gt;cells[0][i][j] = 0;
                else if (*s == &#39;*&#39;) {
                    board-&gt;cells[0][i][j] = 1;
                    ++live;
                }
            }
        }
        if (*s == &#39;\n&#39;)
            ++s;
    }
}

void print_life(life_board_t* board, int gen, int nrow, int ncol)
{
    for (int i = 1; i &lt;= nrow; ++i) {
        for (int j = 1; j &lt;= ncol; ++j)
            printf(board-&gt;cells[gen][i][j] ? &quot;*&quot; : &quot; &quot;);
        printf(&quot;\n&quot;);
    }
}</code></pre>
<p>The actual <code>run_life</code> routine updates the board generation by generation. At each step, we are only reading from the current generation, and have independent writes into the board for the next generation. Note that the outer loop (over generations) is <em>not</em> parallel: each thread runs all the iterations of this outer loop. But we do decorate the inner loop next to be parallelized across the threads, so each thread in the team updates some part of the board. There is an implicit barrier at the end of a parallel for loop unless we include the <code>nowait</code> clause, so each loop switches generations in lockstep.</p>
<pre><code>int run_life(life_board_t* board, int ngens)
{
    #pragma omp parallel
    for (int g = 0; g &lt; ngens; ++g) {
        int current_gen = g%2;
        int next_gen = (g+1)%2;

        #pragma omp for collapse(2)
        for (int i = 1; i &lt; NLIFE-1; ++i) {
            for (int j = 1; j &lt; NLIFE-1; ++j) {

                // Count live neighbors
                int count = -board-&gt;cells[current_gen][i][j];;
                for (int ii = -1; ii &lt;= 1; ++ii)
                    for (int jj = -1; jj &lt;= 1; ++jj)
                        count += board-&gt;cells[current_gen][i+ii][j+jj];

                // Update rule
                if (board-&gt;cells[current_gen][i][j] &amp;&amp;
                    (count == 2 || count == 3))
                    board-&gt;cells[next_gen][i][j] = 1; // Still alive
                else if (!board-&gt;cells[current_gen][i][j] &amp;&amp; count == 3)
                    board-&gt;cells[next_gen][i][j] = 1; // Birth
                else
                    board-&gt;cells[next_gen][i][j] = 0; // Dead
            }
        } // Implicit barrier at end of parallel for
    }
    return ngens%2;
}

void glider_test()
{
    life_board_t board;
    init_life(&amp;board, glider);
    printf(&quot;... Gen 0... :\n&quot;);
    print_life(&amp;board, 0, 6, 8);
    run_life(&amp;board, 12);
    printf(&quot;... Gen 12... :\n&quot;);
    print_life(&amp;board, 0, 6, 8);
}</code></pre>
<h2 id="task-based-list-traversal">Task-based list traversal</h2>
<p>This list traversal code goes through a linked list and creates a task for processing each.</p>
<pre><code>void list_traversal_test()
{
    link_t* head = NULL;
    for (int i = 0; i &lt; 10; ++i)
        list_push2(&amp;head, i);

    #pragma omp parallel
    {
        #pragma omp single nowait
        {
            printf(&quot;Creating tasks from %d\n&quot;, omp_get_thread_num());
            for (link_t* link = head; link; link = link-&gt;next) {
                #pragma omp task firstprivate(link)
                printf(&quot;Process %d on thread %d\n&quot;,
                       link-&gt;data, omp_get_thread_num());
            }
            printf(&quot;Done creating tasks\n&quot;);
         }
     }
}</code></pre>
