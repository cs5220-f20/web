---
title: Load balancing
layout: slides
audio: 2020-11-12-balance
---

<section>
  <h1><a href="https://www.cs.cornell.edu/courses/cs5220/2020fa/">CS 5220</a></h1>
  <h2>Applications of Parallel Computers</h2>
  <h3>Load balancing</h3>
  <p>
    <small>Prof <a href="http://www.cs.cornell.edu/~bindel">David Bindel</a></small>
  </p>
  <p>Please click the play button below.</p>
</section>

<section>
<h3>Inefficiencies in parallel code</h3>
<p><img data-src="figs/lb-red-serial.svg" style="width:40.0%" /></p>
<p>Poor single processor performance</p>
<ul>
<li>Typically in the memory system</li>
<li>Saw this in matrix multiply assignment</li>
</ul>
</section>

<section>
<h3>Inefficiencies in parallel code</h3>
<p><img data-src="figs/lb-red-comm.svg" style="width:40.0%" /></p>
<p>Overhead for parallelism</p>
<ul>
<li>Thread creation, synchronization, communication</li>
<li>Saw this in moshpit and shallow water assignments</li>
</ul>
</section>

<section>
<h3>Inefficiencies in parallel code</h3>
<p><img data-src="figs/lb-red-imbalance.svg" style="width:40.0%" /></p>
<p>Load imbalance</p>
<ul>
<li>Different amounts of work across processors</li>
<li>Different speeds / available resources</li>
<li>Insufficient parallel work</li>
<li>All this can change over phases</li>
</ul>
</section>

<section>
<h3>Where does the time go?</h3>
<ul>
<li>Load balance looks like large sync cost</li>
<li>... maybe so does ordinary sync overhead!</li>
<li>And spin-locks may make sync look like useful work</li>
<li>And ordinary time sharing can confuse things more</li>
<li>Can get some help from profiling tools</li>
</ul>
</section>

<section>
<h3>Many independent tasks</h3>
<p><img data-src="figs/lb-task-circles.svg" style="width:40.0%" /></p>
<ul>
<li>Simplest strategy: partition by task index
<ul>
<li>What if task costs are inhomogeneous?</li>
<li>Worse: all expensive tasks on one thread?</li>
</ul></li>
<li>Potential fixes
<ul>
<li>Many small tasks, randomly assigned</li>
<li>Dynamic task assignment</li>
</ul></li>
<li>Issue: what about scheduling overhead?</li>
</ul>
</section>

<section>
<h3>Variations on a theme</h3>
<p>How to avoid overhead? Chunks!<br />
(Think OpenMP loops)</p>
<ul>
<li>Small chunks: good balance, large overhead</li>
<li>Large chunks: poor balance, low overhead</li>
</ul>
</section>

<section>
<h3>Variations on a theme</h3>
<ul>
<li>Fixed chunk size (requires good cost estimates)</li>
<li>Guided self-scheduling (take <span class="math inline">\(\lceil (\mbox{tasks left})/p \rceil\)</span> work)</li>
<li>Tapering (size chunks based on variance)</li>
<li>Weighted factoring (GSS with heterogeneity)</li>
</ul>
</section>

<section>
<h3>Static dependency</h3>
<p><img data-src="figs/part_esep.svg" style="width:40.0%" /></p>
<ul>
<li>Graph <span class="math inline">\(G = (V,E)\)</span> with vertex and edge weights</li>
<li>Goal: even partition, small cut (comm volume)</li>
<li>Optimal partitioning is NP complete – use heuristics</li>
<li>Tradeoff quality vs speed</li>
<li>Good software exists (e.g. METIS)</li>
</ul>
</section>

<section>
<h3>The limits of graph partitioning</h3>
<p>What if</p>
<ul>
<li>We don’t know task costs?</li>
<li>We don’t know the comm/dependency pattern?</li>
<li>These things change over time?</li>
</ul>
<p>May want <em>dynamic</em> load balancing?</p>
<p>Even in regular case: not every problem looks like an undirected graph!</p>
</section>

<section>
<h3>Dependency graphs</h3>
<p>So far: Graphs for dependencies between <em>unknowns</em>.</p>
<p>For dependency between tasks or computations:</p>
<ul>
<li>Arrow from <span class="math inline">\(A\)</span> to <span class="math inline">\(B\)</span> means that <span class="math inline">\(B\)</span> depends on <span class="math inline">\(A\)</span></li>
<li>Result is a <em>directed acyclic graph</em> (DAG)</li>
</ul>
</section>

<section>
<h3>Example: Longest Common Substring</h3>
<p>Goal: Longest sequence of (not necessarily contiguous) characters common to strings <span class="math inline">\(S\)</span> and <span class="math inline">\(T\)</span>.</p>
<p>Recursive formulation: <span class="math display">\[\begin{aligned}
&amp; \mathrm{LCS}[i,j] = \\
&amp; \begin{cases}
    \max(\mathrm{LCS}[i-1,j], \mathrm{LCS}[j,i-1]), &amp; S[i] \neq T[j] \\
    1 + \mathrm{LCS}[i-1,j-1], &amp; S[i] = T[j]
  \end{cases}
\end{aligned}\]</span> Dynamic programming: Form a table of <span class="math inline">\(\mathrm{LCS}[i,j]\)</span></p>
</section>

<section>
<h3>Dependency graphs</h3>
<p><img data-src="figs/lb-lcs-dependency.svg" style="width:40.0%" /></p>
<p>Process in any order consistent with dependencies.<br />
Limits to available parallel work early on or late!</p>
</section>

<section>
<h3>Dependency graphs</h3>
<p><img data-src="figs/lb-lcs-coarsen.svg" style="width:40.0%" /></p>
<p>Partition into coarser-grain tasks for locality?</p>
</section>

<section>
<h3>Dependency graphs</h3>
<p><img data-src="figs/lb-lcs-coarse3x3.svg" style="width:40.0%" /></p>
<p>Dependence between coarse tasks limits parallelism.</p>
</section>

<section>
<h3>Alternate perspective</h3>
<p>Two approaches to LCS:</p>
<ul>
<li>Solve subproblems from bottom up</li>
<li>Solve top down, <em>memoize</em> common subproblems</li>
</ul>
<p>Parallel question: shared memoization (and synchronize) or independent memoization (and redundant computation)?</p>
</section>

<section>
<h3>Load balancing and task-based parallelism</h3>
<p><img data-src="figs/lb-task-dag.svg" style="width:40.0%" /></p>
<ul>
<li>Task DAG captures data dependencies</li>
<li>May be known at outset or dynamically generated</li>
<li>Topological sort reveals parallelism opportunities</li>
</ul>
</section>

<section>
<h3>Basic parameters</h3>
<ul>
<li>Task costs
<ul>
<li>Do all tasks have equal costs?</li>
<li>Known statically, at creation, at completion?</li>
</ul></li>
<li>Task dependencies
<ul>
<li>Can tasks be run in any order?</li>
<li>If not, when are dependencies known?</li>
</ul></li>
<li>Locality
<ul>
<li>Tasks co-located to reduce communication?</li>
<li>When is this information known?</li>
</ul></li>
</ul>
</section>

<section>
<h3>Task costs</h3>
<figure>
<img data-src="figs/lb-task-eq-circles.svg" alt="Easy: equal unit cost tasks (branch-free loops)" style="width:80.0%" /><figcaption>Easy: equal unit cost tasks (branch-free loops)</figcaption>
</figure>
<figure>
<img data-src="figs/lb-task-circles.svg" alt="Harder: different, known times (sparse MVM)" style="width:80.0%" /><figcaption>Harder: different, known times (sparse MVM)</figcaption>
</figure>
<figure>
<img data-src="figs/lb-task-unk-circles.svg" alt="Hardest: costs unknown until completed (search)" style="width:80.0%" /><figcaption>Hardest: costs unknown until completed (search)</figcaption>
</figure>
</section>

<section>
<h3>Dependencies</h3>
<figure>
<img data-src="figs/lb-deps-easy.svg" alt="Easy: dependency-free loop (Jacobi sweep)" style="width:60.0%" /><figcaption>Easy: dependency-free loop (Jacobi sweep)</figcaption>
</figure>
<figure>
<img data-src="figs/lb-deps-harder.svg" alt="Harder: tasks have predictable structure (some DAG)" style="width:25.0%" /><figcaption>Harder: tasks have predictable structure (some DAG)</figcaption>
</figure>
<figure>
<img data-src="figs/lb-tree-search.svg" alt="Hardest: structure is dynamic (search, sparse LU)" style="width:15.0%" /><figcaption>Hardest: structure is dynamic (search, sparse LU)</figcaption>
</figure>
</section>

<section>
<h3>Locality/communication</h3>
<p>When do you communicate?</p>
<ul>
<li>Easy: Only at start/end (embarrassingly parallel)</li>
<li>Harder: In a predictable pattern (elliptic PDE solver)</li>
<li>Hardest: Unpredictable (discrete event simulation)</li>
</ul>
</section>

<section>
<h3>A spectrum of solutions</h3>
<p>Depending on cost, dependency, locality:</p>
<ul>
<li>Static scheduling</li>
<li>Semi-static scheduling</li>
<li>Dynamic scheduling</li>
</ul>
</section>

<section>
<h3>Static scheduling</h3>
<ul>
<li>Everything known in advance</li>
<li>Can schedule offline (e.g. graph partitioning)</li>
<li>Example: Shallow water solver</li>
</ul>
</section>

<section>
<h3>Semi-static scheduling</h3>
<ul>
<li>Everything known at start of step (for example)</li>
<li>Use offline ideas (e.g. Kernighan-Lin refinement)</li>
<li>Example: Particle-based methods</li>
</ul>
</section>

<section>
<h3>Dynamic scheduling</h3>
<ul>
<li>Don’t know what we’re doing until we’ve started</li>
<li>Have to use online algorithms</li>
<li>Example: most search problems</li>
</ul>
</section>

<section>
<h3>Search problems</h3>
<ul>
<li>Different set of strategies from physics sims!</li>
<li>Usually require dynamic load balance</li>
<li>Example:
<ul>
<li>Optimal VLSI layout</li>
<li>Robot motion planning</li>
<li>Game playing</li>
<li>Speech processing</li>
<li>Reconstructing phylogeny</li>
<li>...</li>
</ul></li>
</ul>
</section>

<section>
<h3>Example: Tree search</h3>
<p><img data-src="figs/lb-tree-search.svg" style="width:40.0%" /></p>
<ul>
<li>Tree unfolds dynamically during search</li>
<li>Common problems on different paths (graph)?</li>
<li>Graph may or may not be explicit in advance</li>
</ul>
</section>

<section>
<h3>Search algorithms</h3>
<p>Generic search:</p>
<ul>
<li>Put root in stack/queue</li>
<li>while stack/queue has work
<ul>
<li>remove node <span class="math inline">\(n\)</span> from queue</li>
<li>if <span class="math inline">\(n\)</span> satisfies goal, return</li>
<li>mark <span class="math inline">\(n\)</span> as searched</li>
<li>queue viable unsearched children<br />
(Can branch-and-bound)</li>
</ul></li>
</ul>
<p>DFS (stack), BFS (queue), A<span class="math inline">\(^*\)</span> (priority queue), ...</p>
</section>

<section>
<h3>Simple parallel search</h3>
<p><img data-src="figs/lb-static-tree.svg" style="width:40.0%" /></p>
<p>Static load balancing:</p>
<ul>
<li>Each new task on a proc until all have a subtree</li>
<li>Ineffective without work estimates for subtrees!</li>
<li>How can we do better?</li>
</ul>
</section>

<section>
<h3>Centralized scheduling</h3>
<p><img data-src="figs/lb-centralq.svg" style="width:50.0%" /></p>
<p>Idea: obvious parallelization of standard search</p>
<ul>
<li>Locks on shared data structure (stack, queue, etc)</li>
<li>Or might be a manager task</li>
</ul>
</section>

<section>
<h3>Centralized scheduling</h3>
<p>Teaser: What could go wrong with this parallel BFS?</p>
<ul>
<li>Queue root and fork
<ul>
<li>obtain queue lock</li>
<li>while queue has work
<ul>
<li>remove node <span class="math inline">\(n\)</span> from queue</li>
<li>release queue lock</li>
<li>process <span class="math inline">\(n\)</span>, mark as searched</li>
<li>obtain queue lock</li>
<li>enqueue unsearched children</li>
</ul></li>
<li>release queue lock</li>
</ul></li>
<li>join</li>
</ul>
</section>

<section>
<h3>Centralized scheduling</h3>
<p>Teaser: What could go wrong with this parallel BFS?</p>
<ul>
<li>Put root in queue; <strong>workers active = 0</strong>; fork
<ul>
<li>obtain queue lock</li>
<li>while queue has work <strong>or workers active &gt; 0</strong>
<ul>
<li>remove node <span class="math inline">\(n\)</span> from queue; <strong>workers active ++</strong></li>
<li>release queue lock</li>
<li>process <span class="math inline">\(n\)</span>, mark as searched</li>
<li>obtain queue lock</li>
<li>enqueue unsearched children; <strong>workers active –</strong></li>
</ul></li>
<li>release queue lock</li>
</ul></li>
<li>join</li>
</ul>
</section>

<section>
<h3>Centralized task queue</h3>
<ul>
<li>Called <em>self-scheduling</em> when applied to loops
<ul>
<li>Tasks might be range of loop indices</li>
<li>Assume independent iterations</li>
<li>Loop body has unpredictable time (or do it statically)</li>
</ul></li>
<li>Pro: dynamic, online scheduling</li>
<li>Con: centralized, so doesn’t scale</li>
<li>Con: high overhead if tasks are small</li>
</ul>
</section>

<section>
<h3>Beyond centralized task queue</h3>
<p><img data-src="figs/lb-distq.svg" style="width:80.0%" /></p>
</section>

<section>
<h3>Beyond centralized task queue</h3>
<p>Basic <em>distributed</em> task queue idea:</p>
<ul>
<li>Each processor works on part of a tree</li>
<li>When done, get work from a peer</li>
<li><em>Or</em> if busy, push work to a peer</li>
<li>Requires asynch communication</li>
</ul>
<p>Also goes by work stealing, work crews...</p>
<p>Implemented in OpenMP, Cilk, X10, CUDA, QUARK, SMPss, ...</p>
</section>

<section>
<h3>Picking a donor</h3>
<p>Could use:</p>
<ul>
<li>Asynchronous round-robin</li>
<li>Global round-robin (current donor ptr at P0)</li>
<li>Randomized – optimal with high probability!</li>
</ul>
</section>

<section>
<h3>Diffusion-based balancing</h3>
<ul>
<li>Problem with random polling: communication cost!
<ul>
<li>But not all connections are equal</li>
<li>Idea: prefer to poll more local neighbors</li>
</ul></li>
<li>Average out load with neighbors <span class="math inline">\(\implies\)</span> diffusion!</li>
</ul>
</section>

<section>
<h3>Mixed parallelism</h3>
<ul>
<li>Today: mostly coarse-grain <em>task</em> parallelism</li>
<li>Other times: fine-grain <em>data</em> parallelism</li>
<li>Why not do both? <em>Switched</em> parallelism.</li>
</ul>
</section>

<section>
<h3>Takeaway</h3>
<ul>
<li>Lots of ideas, not one size fits all!</li>
<li>Axes: task size, task dependence, communication</li>
<li>Dynamic tree search is a particularly hard case!</li>
<li>Fundamental tradeoffs
<ul>
<li>Overdecompose (load balance) vs<br />
keep tasks big (overhead, locality)</li>
<li>Steal work globally (balance) vs<br />
steal from neighbors (comm. overhead)</li>
</ul></li>
<li>Sometimes hard to know when code should stop!</li>
</ul>
</section>

