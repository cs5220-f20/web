---
title: Particle systems
layout: slides
audio: 2020-09-29-particle
---

<section>
  <h1><a href="https://www.cs.cornell.edu/courses/cs5220/2020fa/">CS 5220</a></h1>
  <h2>Applications of Parallel Computers</h2>
  <h3>Particle Systems</h3>
  <p>
    <small>Prof <a href="http://www.cs.cornell.edu/~bindel">David Bindel</a></small>
  </p>
  <p>Please click the play button below.</p>

  <aside class="notes">
    Welcome to our discussion of a second class of physical
    simulations in our lightning introduction to locality and
    parallelism in simulations.  In this deck, we are talking about
    particle systems.
  </aside>
</section>


<section>
  <h3>Particle systems</h3>

  <ul>
    <li>Billiards, electrons, galaxies, ...</li>
    <li>Ants, cars, agents, ...?</li>
  </ul>

  <aside class="notes">
    When I say particles, I mean all types of discrete interacting
    entities.  That might include simple physical things, from billiard balls
    to electrons to galaxies; or it might include ants in a colony,
    cars on a highway, or agents in the Matrix (or in an agent-based
    simulation, if you're not a Keanu Reeves fan).
  </aside>
</section>


<section>
  <h3>Particle simulation</h3>
  <p>Particles move via Newton (<span class="math inline">\(F = ma\)</span>), with</p>
  <ul>
    <li>External forces: ambient gravity, currents, etc.</li>
    <li>Local forces: collisions, Van der Waals (<span class="math inline">\(1/r^6\)</span>), etc.</li>
    <li>Far-field forces: gravity and electrostatics (<span class="math inline">\(1/r^2\)</span>), etc.
      <ul>
        <li>Simple approximations often apply (Saint-Venant)</li>
    </ul></li>
  </ul>

  <aside class="notes">
    When we are dealing with physical particles, we generally have
    them moving around according to Newton's force balance law.  The
    interesting thing is where the forces come from!  Sometimes they
    are external, things like gravity or currents that come from
    outside the scope of the things we are trying to simulate.
    Sometimes, they involve interactions between particles that are
    very close to each other.  And sometimes they involve far-field
    forces like gravitational attraction or electrostatic attraction
    or repulsion - though, as we have mentioned before, these types of
    far-field forces sometimes admit convenient approximations.
  </aside>
</section>


<section>
  <h3>A forced example</h3>
  <p>Example force: <span class="math display">\[f_i = \sum_j Gm_i m_j
      \frac{(x_j-x_i)}{r_{ij}^3}
      \left(1 - \left(\frac{a}{r_{ij}}\right)^{4} \right), \qquad
      r_{ij} = \|x_i-x_j\|\]</span></p>
  <ul>
    <li>Long-range attractive force (<span class="math inline">\(r^{-2}\)</span>)</li>
    <li>Short-range repulsive force (<span class="math inline">\(r^{-6}\)</span>)</li>
    <li>Go from attraction to repulsion at radius <span class="math inline">\(a\)</span></li>
  </ul>

  <aside class="notes">
    So here's the type of thing we might consider.  Suppose that our
    particles have a short-range repulsive force and a long-range
    attractive force.  They can't get away from each other, and can't
    get too close.  What happens?  Interesting things!  Depends a lot
    on how much energy there is in the initial state of the system.
  </aside>
</section>


<section>
  <h3>A simple serial simulation</h3>
  <p>In <span class="smallcaps">Matlab</span>, we can write</p>
  <pre><code>npts = 100;
t = linspace(0, tfinal, npts);
[tout, xyv] = ode113(@fnbody, t, [x; v], [], m, g);
xout = xyv(:,1:length(x))&#39;;</code></pre>
  <p>... but I can’t call ode113 in C in parallel (or can I?)</p>

  <aside class="notes">
    At the end of the day, the particles are governed by a collection
    of ordinary differential equations.  So maybe one could consider
    using a standard ODE solver, like one of the ones in MATLAB, to
    solve the system.  This is not such a stupid idea, really.  But it
    turns out that we might want to think again, both for parallelism
    and to get the properties that we want out of our ODE solver.
  </aside>
</section>


<section>
  <h3>A simple serial simulation</h3>
  <p>Maybe a fixed step leapfrog will do?</p>
  <pre><code>npts = 100;
steps_per_pt = 10;
dt = tfinal/(steps_per_pt*(npts-1));
xout = zeros(2*n, npts);
xout(:,1) = x;
for i = 1:npts-1
  for ii = 1:steps_per_pt
    x = x + v*dt;
    a = fnbody(x, m, g);
    v = v + a*dt;
  end
  xout(:,i+1) = x;
end</code></pre>

  <aside class="notes">
    The standard ODE solvers are pretty accurate for medium lengths of
    time, but they do have some error due to approximating an ODE by
    something that involves discrete time steps.  Unfortunately,
    varying the step size to maintain exact accuracy often doesn't get
    us quite what we want.  It is OK if we mess up some details, as
    long as others are well preserved.  In physics, for example, we
    usually want conservation of energy and momentum, and some simple
    integrators with fixed step sizes - like the leap frog scheme
    shown above - may do that even better than the MATLAB ODE solver.
    Fixed step leapfrog is easier to code, too!
  </aside>
</section>


<section>
  <h3>Plotting particles</h3>
  <figure>
    <img data-src="figs/sph-plot.png" alt="image" style="width:90.0%"
    /><figcaption>Smooth Particle Hydrodynamics (SPH) simulation</figcaption>
  </figure>

  <aside class="notes">
    You'll get to play with this integrator soon enough for yourself.
    The plan is that the next project will involve a smoothed particle
    hydrodynamics or SPH simulation, and we'll use leapfrog for the
    time integration.
  </aside>
</section>


<section>
  <h3>Pondering particles</h3>
  <ul>
    <li>Where do particles <q>live</q> (distributed mem)?
      <ul>
        <li>Decompose in space? By particle number?</li>
        <li>What about clumping?</li>
    </ul></li>
    <li>How are long-range force computations organized?</li>
    <li>How are short-range force computations organized?</li>
    <li>How is force computation load balanced?</li>
    <li>What are the boundary conditions?</li>
    <li>How are potential singularities handled?</li>
    <li>What integrator is used? What step control?</li>
  </ul>

  <aside class="notes">
    <p>
      We'll say more about time steppers on Thursday.  But the more
      interesting thing to talk about at the moment is how we manage the
      data for the particles and the computation of the forces between
      them at any given step.  We also have to worry about things like
      what happens at boundaries - do we bounce off walls, or does
      something else happen?  And sometimes we have to worry about the
      potential that our model has singular behaviors, like infinite
      attraction between particles that are zero distance apart.  Of
      course, that type of interaction usually means that we have
      neglected some important part of the physics, but that's cold
      comfort when we're trying to sort out why there are NaNs
      suddenly appearing in our simulations!
    </p>
  </aside>
</section>


<section>
  <h3>External forces</h3>
  <p>Simplest case: no particle interactions.</p>
  <ul>
    <li>Embarrassingly parallel (like Monte Carlo)!</li>
    <li>Could just split particles evenly across processors</li>
    <li>Is it that easy?
      <ul>
        <li>Maybe some trajectories need short time steps?</li>
        <li>Even with MC, load balance may not be trivial!</li>
    </ul></li>
  </ul>
</section>


<section>
  <h3>Local forces</h3>
  <img src="{{ "lec/figs/local-forces-dd1.svg" | relative_url }}"
       alt="Domain decomposition for local forces"
       style="background-color:white"
       width="25%"/>
  <ul>
    <li>Simplest all-pairs check is <span class="math inline">\(O(n^2)\)</span> (expensive)</li>
    <li>Or only check close pairs (via binning, quadtrees?)</li>
    <li>Communication required for pairs checked</li>
    <li>Usual model: domain decomposition</li>
  </ul>
</section>


<section>
  <h3>Local forces: Communication</h3>
  <img src="{{ "lec/figs/local-forces-dd2.svg" | relative_url }}"
       alt="Domain decomposition for local forces"
       style="background-color:white"
       width="25%"/>
  <p>Minimize communication:</p>
  <ul>
    <li>Send particles that might affect a neighbor “soon”</li>
    <li>Trade extra computation against communication</li>
    <li>Want low surface area-to-volume ratios on domains</li>
  </ul>
</section>


<section>
  <h3>Local forces: Load balance</h3>
  <img src="{{ "lec/figs/local-forces-dd3.svg" | relative_url }}"
       alt="Domain decomposition for local forces"
       style="background-color:white"
       width="25%"/>
  <ul>
    <li>Are particles evenly distributed?</li>
    <li>Do particles remain evenly distributed?</li>
    <li>Can divide space unevenly (e.g. quadtree/octtree)</li>
  </ul>
</section>


<section>
  <h3>Far-field forces</h3>
  <ul>
    <li>Every particle affects every other particle</li>
    <li>All-to-all communication required
      <ul>
        <li>Overlap communication with computation</li>
        <li>Poor memory scaling if everyone keeps everything!</li>
    </ul></li>
    <li>Idea: pass particles in a round-robin manner</li>
  </ul>
</section>


<section>
  <h3>Passing particles (far-field forces)</h3>
  <img src="{{ "lec/figs/far-field-rr1.svg" | relative_url }}"
       alt="Domain decomposition for local forces"
       style="background-color:white"
       width="60%"/>
  <pre>copy local particles to current buf
for phase = 1:p
  send current buf to rank+1 (mod p)
  recv next buf from rank-1 (mod p)
  interact local particles with current buf
  swap current buf with next buf
end</pre>
</section>


<section>
  <h3>Passing particles (far-field forces)</h3>
  <p>Suppose <span class="math inline">\(n = N/p\)</span> particles in buffer. At each phase <span class="math display">\[\begin{aligned}
      t_{\mathrm{comm}} &amp; \approx \alpha + \beta n \\
      t_{\mathrm{comp}} &amp; \approx \gamma n^2
      \end{aligned}\]</span> So we can mask communication with computation if <span class="math display">\[n \geq
      \frac{1}{2\gamma} \left( \beta + \sqrt{\beta^2 + 4 \alpha \gamma} \right)
      &gt; \frac{\beta}{\gamma}\]</span></p>
</section>


<section>
  <h3>Passing particles (far-field forces)</h3>
  <p>More efficient serial code<br />
    <span class="math inline">\(\implies\)</span> larger <span class="math inline">\(n\)</span> needed to mask communication!<br />
    <span class="math inline">\(\implies\)</span> worse speed-up as <span class="math inline">\(p\)</span> gets larger (fixed <span class="math inline">\(N\)</span>)<br />
    but scaled speed-up (<span class="math inline">\(n\)</span> fixed) remains unchanged.</p>
  <p>This analysis neglects overhead term in LogP.</p>
</section>


<section>
  <h3>Far-field forces: particle-mesh methods</h3>
  <p>Consider <span class="math inline">\(r^{-2}\)</span> electrostatic potential interaction</p>
  <ul>
    <li>Enough charges looks like a continuum!</li>
    <li>Poisson maps charge distribution to potential</li>
    <li>Fast Poisson for regular grids (FFT, multigrid)</li>
    <li>Approx depends on mesh and particle density</li>
    <li>Can clean up leading part of approximation error</li>
  </ul>
</section>


<section>
  <h3>Far-field forces: particle-mesh</h3>
  <img src="{{ "lec/figs/particle-in-cell.svg" | relative_url }}"
       alt="Domain decomposition for local forces"
       style="background-color:white"
       width="25%"/>
  <ul>
    <li>Map particles to mesh points (multiple strategies)</li>
    <li>Solve potential PDE on mesh</li>
    <li>Interpolate potential to particles</li>
    <li>Add correction term – acts like local force</li>
  </ul>
</section>


<section>
  <h3>Far-field forces: tree methods</h3>
  <img src="{{ "lec/figs/tree-code.svg" | relative_url }}"
       alt="Domain decomposition for local forces"
       style="background-color:white"
       width="40%"/>
  <ul>
    <li>Distance simplifies things
      <ul>
        <li>Andromeda looks like a point mass from here?</li>
    </ul></li>
    <li>Build a tree, approx descendants at each node</li>
    <li>Variants: Barnes-Hut, FMM, Anderson’s method</li>
    <li>More on this later in the semester</li>
  </ul>
</section>


<section>
  <h3>Summary of particle example</h3>
  <ul>
    <li>Model: Continuous motion of particles
      <ul>
        <li>Could be electrons, cars, whatever...</li>
    </ul></li>
    <li>Step through discretized time</li>
  </ul>
</section>


<section>
  <h3>Summary of particle example</h3>
  <ul>
    <li>Local interactions
      <ul>
        <li>Relatively cheap</li>
        <li>Load balance a pain</li>
    </ul></li>
    <li>All-pairs interactions
      <ul>
        <li>Obvious algorithm is expensive (<span class="math inline">\(O(n^2)\)</span>)</li>
        <li>Particle-mesh and tree-based algorithms help</li>
    </ul></li>
  </ul>
  <p>An important special case of lumped/ODE models.</p>
</section>

